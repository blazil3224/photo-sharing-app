# E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
# è¦ä»¶: CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œè¨­å®š

name: E2E Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # æ¯æ—¥åˆå‰2æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.9'

jobs:
  e2e-tests:
    runs-on: ubuntu-latest
    
    services:
      # DynamoDB Local
      dynamodb:
        image: amazon/dynamodb-local:latest
        ports:
          - 8000:8000
        options: >-
          --health-cmd "curl -f http://localhost:8000 || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      # LocalStack (S3ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)
      localstack:
        image: localstack/localstack:latest
        ports:
          - 4566:4566
        env:
          SERVICES: s3
          DEBUG: 1
          DATA_DIR: /tmp/localstack/data
        options: >-
          --health-cmd "curl -f http://localhost:4566/health || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    strategy:
      matrix:
        test-suite: [unit, integration, e2e, performance, security]
      fail-fast: false

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: |
          frontend/package-lock.json
          backend/requirements.txt

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('backend/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install backend dependencies
      run: |
        cd backend
        pip install -r requirements.txt

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Setup test environment
      run: |
        # ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
        echo "NODE_ENV=test" >> $GITHUB_ENV
        echo "CI=true" >> $GITHUB_ENV
        echo "REACT_APP_API_URL=http://localhost:5000" >> $GITHUB_ENV
        echo "REACT_APP_ENVIRONMENT=test" >> $GITHUB_ENV
        echo "AWS_ACCESS_KEY_ID=test" >> $GITHUB_ENV
        echo "AWS_SECRET_ACCESS_KEY=test" >> $GITHUB_ENV
        echo "AWS_DEFAULT_REGION=ap-northeast-1" >> $GITHUB_ENV
        echo "DYNAMODB_ENDPOINT=http://localhost:8000" >> $GITHUB_ENV
        echo "S3_ENDPOINT=http://localhost:4566" >> $GITHUB_ENV

    - name: Wait for services
      run: |
        # DynamoDB Localã®èµ·å‹•ã‚’å¾…æ©Ÿ
        timeout 60 bash -c 'until curl -f http://localhost:8000; do sleep 2; done'
        
        # LocalStackã®èµ·å‹•ã‚’å¾…æ©Ÿ
        timeout 60 bash -c 'until curl -f http://localhost:4566/health; do sleep 2; done'

    - name: Initialize test database
      run: |
        cd backend
        python scripts/test_models.py

    - name: Start backend server
      run: |
        cd backend
        python app.py &
        
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’å¾…æ©Ÿ
        timeout 60 bash -c 'until curl -f http://localhost:5000/health; do sleep 2; done'

    - name: Run ${{ matrix.test-suite }} tests
      run: |
        cd frontend
        npm run test:${{ matrix.test-suite }}
      env:
        CI: true
        NODE_ENV: test

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.test-suite }}
        path: |
          frontend/test-reports/
          frontend/coverage/
        retention-days: 30

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.test-suite == 'e2e'
      with:
        file: frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

    - name: Comment PR with test results
      uses: actions/github-script@v6
      if: github.event_name == 'pull_request' && always()
      with:
        script: |
          const fs = require('fs');
          const path = 'frontend/test-reports/test-results.json';
          
          if (fs.existsSync(path)) {
            const results = JSON.parse(fs.readFileSync(path, 'utf8'));
            
            const body = `## ğŸ§ª Test Results - ${{ matrix.test-suite }}
            
            | Metric | Value |
            |--------|-------|
            | Total Tests | ${results.totalTests} |
            | Passed | âœ… ${results.passedTests} |
            | Failed | âŒ ${results.failedTests} |
            | Duration | ${Math.round(results.duration / 1000)}s |
            ${results.coverage ? `| Coverage | ${results.coverage.lines}% lines` : ''}
            
            ${results.errors.length > 0 ? `### âŒ Errors\n${results.errors.map(e => `- ${e}`).join('\n')}` : ''}
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
          }

  # ãƒ†ã‚¹ãƒˆçµæœã®é›†ç´„
  test-summary:
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: always()
    
    steps:
    - name: Download all test results
      uses: actions/download-artifact@v3
      with:
        path: test-results

    - name: Generate summary report
      run: |
        echo "# ğŸ“Š Test Summary Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        for suite in unit integration e2e performance security; do
          if [ -f "test-results/test-results-$suite/test-results.json" ]; then
            echo "## $suite Tests" >> $GITHUB_STEP_SUMMARY
            
            # JSONã‹ã‚‰çµæœã‚’æŠ½å‡ºã—ã¦Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã«å¤‰æ›
            python3 -c "
import json
import sys

try:
    with open('test-results/test-results-$suite/test-results.json', 'r') as f:
        data = json.load(f)
    
    print('| Metric | Value |')
    print('|--------|-------|')
    print(f'| Total Tests | {data.get(\"totalTests\", 0)} |')
    print(f'| Passed | âœ… {data.get(\"passedTests\", 0)} |')
    print(f'| Failed | âŒ {data.get(\"failedTests\", 0)} |')
    print(f'| Duration | {round(data.get(\"duration\", 0) / 1000)}s |')
    
    if data.get('coverage'):
        print(f'| Coverage | {data[\"coverage\"][\"lines\"]}% lines |')
    
    print('')
except Exception as e:
    print(f'Error processing results for $suite: {e}')
            " >> $GITHUB_STEP_SUMMARY
          fi
        done

    - name: Check test status
      run: |
        failed_suites=""
        
        for suite in unit integration e2e performance security; do
          if [ -f "test-results/test-results-$suite/test-results.json" ]; then
            failed_tests=$(python3 -c "
import json
try:
    with open('test-results/test-results-$suite/test-results.json', 'r') as f:
        data = json.load(f)
    print(data.get('failedTests', 0))
except:
    print(0)
            ")
            
            if [ "$failed_tests" -gt 0 ]; then
              failed_suites="$failed_suites $suite"
            fi
          fi
        done
        
        if [ -n "$failed_suites" ]; then
          echo "âŒ Tests failed in suites:$failed_suites"
          exit 1
        else
          echo "âœ… All test suites passed"
        fi

  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å›å¸°ãƒ†ã‚¹ãƒˆ
  performance-regression:
    runs-on: ubuntu-latest
    needs: e2e-tests
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Download performance test results
      uses: actions/download-artifact@v3
      with:
        name: test-results-performance
        path: current-results

    - name: Get baseline performance data
      run: |
        # mainãƒ–ãƒ©ãƒ³ãƒã®æœ€æ–°ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        git checkout origin/main
        
        # éå»ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å–å¾—
        if [ -f "performance-baseline.json" ]; then
          cp performance-baseline.json baseline-results/
        fi

    - name: Compare performance
      run: |
        python3 -c "
import json
import sys

def load_json(path):
    try:
        with open(path, 'r') as f:
            return json.load(f)
    except:
        return {}

current = load_json('current-results/test-results.json')
baseline = load_json('baseline-results/performance-baseline.json')

if not current or not baseline:
    print('Performance comparison skipped - missing data')
    sys.exit(0)

current_duration = current.get('duration', 0)
baseline_duration = baseline.get('duration', 0)

if baseline_duration > 0:
    regression_percent = ((current_duration - baseline_duration) / baseline_duration) * 100
    
    print(f'Performance comparison:')
    print(f'Current: {current_duration}ms')
    print(f'Baseline: {baseline_duration}ms')
    print(f'Change: {regression_percent:+.1f}%')
    
    if regression_percent > 20:  # 20%ä»¥ä¸Šã®åŠ£åŒ–ã§è­¦å‘Š
        print('âš ï¸ Performance regression detected!')
        sys.exit(1)
    elif regression_percent < -10:  # 10%ä»¥ä¸Šã®æ”¹å–„
        print('ğŸš€ Performance improvement detected!')
    else:
        print('âœ… Performance within acceptable range')
else:
    print('No baseline data available for comparison')
        "

  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
  security-scan:
    runs-on: ubuntu-latest
    needs: e2e-tests
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run npm audit
      run: |
        cd frontend
        npm audit --audit-level moderate

    - name: Run Snyk security scan
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      with:
        args: --severity-threshold=medium
        command: test

    - name: Upload security scan results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-scan-results
        path: |
          snyk-results.json
        retention-days: 30